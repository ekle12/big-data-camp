{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data: An Introduction to Pandas and DataFrames\n",
    "\n",
    "Pandas is a powerful Python library that is essential for data science and analysis. It provides high-performance, easy-to-use data structures, the most important of which is the DataFrame. You can think of a DataFrame as a smart, programmable spreadsheet, like Excel or Google Sheets, but with the full power of Python behind it.\n",
    "\n",
    "Here we'll look into the structure of a dataframe and walk through the most critical first steps to take immediately after loading a dataset into a pandas as a dataframe. Think of this as the initial \"health check\" for your data, a fundamental skill for any data analyst or scientist.\n",
    "\n",
    "Why is this so important? Before you can perform any meaningful analysis, build a model, or create a visualization, you must first understand the data you're working with.  Mastering these first few commands builds a solid foundation for all your future data work and prevents common errors down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures (cont.)\n",
    "\n",
    "We have already seen a couple examples of **structured data**: lists and dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists\n",
    "\n",
    "Lists are **ordered**, meaning the items are labeled using an **index**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list = [\"eggs\", \"milk\", \"juice\"]   \n",
    "\n",
    "# Print \"milk\"\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays\n",
    "\n",
    "Arrays are a special type of list that contains only one data type. This homogeneity allows for more efficient memory usage and faster numerical computations, making them a favorite in scientific computing. Arrays are typically more rigid than lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which list is an array?\n",
    "planet_list = ['mercury', 'venus', 'earth', 'mars', 'jupiter']\n",
    "age_list = [3, 8, 12.0, 38, 40]\n",
    "number_list = [4, 'five', 'ten', 32]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key takeaway for both lists and arrays is their integer-based indexing. You retrieve an element by its numerical position, starting from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tabular Powerhouse: DataFrames\n",
    "Enter the dataframe, a structure that brings together the concepts of lists, arrays, and dictionaries to create a powerful tool for data analysis. A dataframe is a two-dimensional data structure with labeled rows and columns. Imagine a spreadsheet, and you have a good mental model of a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing the Pandas Library\n",
    "\n",
    "In order to have access to the functions in a library, we have to \"import\" it. This is done with a simple line of code. A common practice it to:\n",
    "\n",
    "`import <library_name> as <abbreviated_name>`. \n",
    "\n",
    "This allows us to define an abbreviation for the library to use whenever we call a function from it instead of typing out the full name of the library every time. The abbreviation is up to you, but most libraries have an agreed upon abbreviation. For examples, most people abbreviate pandas as `pd`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pandas dataframe should look familiar. It is how data is structured in spreadsheets like Excel and Google Sheets. The bold numbers on the left are known as the **index** and allow us to number rows. The column names allow us to label and reference individual arrays in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading in Data to a DataFrame a from a .csv File\n",
    "\n",
    "It is possible to create a dataframe from scratch, but we usualliy will bring in data from an existing file, also known as a **dataset**. The most common file format for raw data is a `.csv` file, short for \"comma separated values\" and it is very easy to bring into as a dataframe using the `pd.read_csv()` function.\n",
    "\n",
    "When you use `pd.read_csv('filename.csv')`, you're telling pandas to find a file and load it into a DataFrame. The string you provide inside the parentheses is the **file path**. It's the set of directions from your current location to the file you want.\n",
    "\n",
    "See the \"Supplementary Information\" section for more on file paths.\n",
    "\n",
    "Now we will look at an authentic dataset of historical global temperatures, courtesy of [Berkeley Earth](https://berkeleyearth.org/about/), which is affiliated with [Lawrence Berkeley National Laboratory](https://www.lbl.gov/).\n",
    "\n",
    "The file is located at: https://raw.githubusercontent.com/jdomyancich/big-data-camp/refs/heads/main/data/global_temps.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a First Look\n",
    "\n",
    "Once you've loaded your dataset into a pandas DataFrame using `pd.read_csv()`, the crucial next step is to get a feel for your data. This initial inspection helps you understand its structure, identify potential issues like missing values, and get a sense of the data's content.\n",
    "\n",
    "Here are the essential dataframe methods and attributes you should use right away. Remember, a dataframe is an **object**, meaning it has certain **methods** associated with it. In pandas (and Python in general), an **attribute** is a piece of data or a characteristic stored on an object, which you access directly by name. Think of it as a property of the object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.head()` - View the first few rows\n",
    "This is the most common first step. It shows you the first 5 rows of your DataFrame by default, giving you an immediate look at your columns and the type of data they contain.\n",
    "\n",
    "**Why it's useful**: It's a quick way to confirm your data loaded correctly and to see the column names and data examples without printing the entire (potentially massive) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.tail()` - View the last few rows\n",
    "Similar to `.head()`, this method shows you the last 5 rows of your DataFrame.\n",
    "\n",
    "**Why it's useful**: This can help you spot any issues with the end of your file, such as summary rows or trailing blank data that might have been loaded incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.shape` - Check the dimensions\n",
    "This is an attribute (not a method, so no parentheses) that returns a tuple representing the dimensions of the DataFrame: `(number_of_rows, number_of_columns)`. \n",
    "\n",
    "**Why it's useful**: It tells you exactly how big your dataset is, which is fundamental information for any further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.info()` - Get a technical summary\n",
    "\n",
    "This method provides a concise technical summary of the dataframe. It's one of the most valuable inspection tools.\n",
    "\n",
    "**Why it's useful**:\n",
    "- Index type: Shows the index type and range.\n",
    "- Column count: Confirms the total number of columns.\n",
    "- Dtype: Shows the data type (e.g., `int64`, `float64`, `object`) for each column. An object dtype often means the column contains strings.\n",
    "- Memory usage: Gives you an idea of how much memory the dataframe is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.describe()` - Generate descriptive statistics\n",
    "\n",
    "This method generates descriptive statistics for the numerical columns in your dataframe.\n",
    "\n",
    "**Why it's useful**: It provides a quick overview of the distribution, central tendency, and spread of your numerical data. You can quickly spot things like outliers (e.g., a huge max value) or unexpected distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Wrangling\n",
    "\n",
    "This is one of the hardest parts of working with data. Raw data is rarely ready to be analyzed. Scientists spend a lot of time manipulating their data to get it into a form that can be used. We call it \"wrangling\".\n",
    "\n",
    "<img src = 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/Cats_in_aoshima_island_1.JPG/1600px-Cats_in_aoshima_island_1.JPG' width = 400>\n",
    "\n",
    "Possible problems with data:\n",
    "* Getting only the data you need \n",
    "* Incorrect data types\n",
    "* Incorrect units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Columns\n",
    "\n",
    "You can think of the data frame from two perspectives: columns and rows. Columns are much easier to work with because they are arrays, meaning all the elements in a column are the same datatype (or they should be)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.columns` - View column names\n",
    "\n",
    "This attribute returns a list of all the column names in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the original column names are confusing. You can change them by setting a list of new column names to `data.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "global_temps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Columns\n",
    "\n",
    "The most common way to get data from a DataFrame is by selecting one or more columns. Remember, each column is an array, meaning all the elements in a column are the same datatype (or they should be)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a Single Column\n",
    "To select a single column, use square bracket notation with the column name as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the city column\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Multiple Columns\n",
    "\n",
    "To select multiple columns, you need to pass a **list** of column names inside the square brackets. This will return a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "selected_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Filtering (Boolean Indexing)\n",
    "\n",
    "This is one of the most powerful features of Pandas: selecting rows based on whether they meet a certain condition. You pass a Series of `True`/`False` values (a \"Boolean Series\") inside the square brackets. Only rows where the value is `True` will be returned. The easiest way to undrstand this is by breaking it down, step by step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Create a condition**\n",
    "\n",
    "Let's ask a question: \"Which cities have experienced very hot average temperature for a specific month?\" Let's say 35&deg;C (95&deg;F) is \"very hot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Generate the Boolean Series**\n",
    "\n",
    "If you `print(hot_cities)`, you wouldn't see the cities. You would see the Boolean Series—the `True`/`False` answer for every single city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hot_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Use the Boolean Series to filter the dataframe**\n",
    "Now, you use that condition (the Boolean Series) as a filter inside the square brackets of your original dataframe.\n",
    "\n",
    "Pandas will look at your `global_temps` dataframe, and for every row, it will check the corresponding value in your condition series. It will only keep the rows where the value is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "high_temps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Conditions\n",
    "\n",
    "You can combine multiple conditions using logical operators:\n",
    "\n",
    "- & for AND (both conditions must be true)\n",
    "- | for OR (at least one condition must be true)\n",
    "\n",
    "Remember to put each condition in parentheses!\n",
    "\n",
    "`(first_condition) & (second_condition)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "hot_india = global_temps[condition]\n",
    "hot_india.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about rows?\n",
    "\n",
    "Rows are a little trickier to reference because they are not arrays. In columns, we can reference the name of the columns that we are interested in. Also, the elements in a column are the same data type. Since rows contain the elements of several different arrays, they can contain multiple data types and require a different way of thinking. We can filter rows two ways: by index or by label.\n",
    "\n",
    "For the `iloc` method, you can pass a number `[5]`, range of numbers `[5:9]`, list `[23, 45, 87]`. These values correspond to the bold index values in the first column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a value\n",
    "hot_india.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a range\n",
    "hot_india.iloc[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a list\n",
    "hot_india.iloc[[1, 3, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `loc` method allows you to search for labels within the columns. You can use values, booleans, and conditionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a conditional\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass multiple conditionals\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Values\n",
    "\n",
    "The temperatures for all the cities are in Celsius. Let's convert them to Fahrenheit so they are easier to understand.\n",
    "\n",
    "$$ T(F) = \\frac{9}{5}T(C)+32 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function for converting Celsius to Fahrenheit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Apply\" the function to the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_temps['ave_temp_F'] = global_temps['ave_temp'].apply(C_to_F)\n",
    "global_temps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "In the realm of scientific computing, the ability to effectively analyze (pick apart) and interpret data is paramount. Whether you're working with experimental results, observational data, or simulations, understanding how to systematically process and summarize your data is crucial for drawing valid conclusions and advancing scientific knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with `groupby()`\n",
    "\n",
    "The `groupby()` method is one of the most powerful and frequently used functions in Pandas for data analysis. It allows you to split your data into groups based on some criteria, apply a function to each group independently, and then combine the results into a single dataframe or series. This process is often referred to as \"split-apply-combine.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it Works (The \"Split-Apply-Combine\" Strategy):\n",
    "\n",
    "1. **Split**: Pandas divides the dataframe into multiple sub-dataframes, where each sub-dataframe contains rows that share the same value for the specified grouping key(s).\n",
    "\n",
    "2. **Apply**: An aggregation function (like `mean()`, `sum()`, `count()`, `max()`, `min()`, `median()`, `std()`, `var()`, or even custom functions) is applied to each individual group.\n",
    "\n",
    "3. **Combine**: The results of the applied function from all the individual groups are then combined back into a single series or dataframe, with the grouping keys becoming the new index.\n",
    "\n",
    "All of this can be done with a single line of code:\n",
    "\n",
    "`df.groupby('split_group')[data_to_be_applied].function_applied_to_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can group the cities by country and then calculate the average temperature for each country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "country_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
